{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The data contains a pair of paragraphs. These text paragraphs are randomly sampled from a raw dataset. Each pair of the sentence may or may not be semantically similar. The dataset considered for this project does not contain any labels. Given below is the solution to the unsupervised machine learning problem"
      ],
      "metadata": {
        "id": "a3HBkj132F4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GMJYfBQ3gqt",
        "outputId": "eed2a1ec-9aa3-4d92-8b97-260334b31e09"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import nltk\n",
        "import re\n",
        "import scipy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec, KeyedVectors, FastText\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Flatten, SimpleRNN, RNN,GRU, SpatialDropout1D, Dropout\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import sklearn\n",
        "\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-11-09T13:04:46.736313Z",
          "iopub.execute_input": "2022-11-09T13:04:46.737247Z",
          "iopub.status.idle": "2022-11-09T13:04:55.529143Z",
          "shell.execute_reply.started": "2022-11-09T13:04:46.737141Z",
          "shell.execute_reply": "2022-11-09T13:04:55.527768Z"
        },
        "trusted": true,
        "id": "Xmvx-ytI2F4i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.DataFrame()\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "data.shape\n",
        "#data.head()\n",
        "#print(data.shape)\n",
        "#print(data.head())\n",
        "dictionary={}\n",
        "for word in range(data.shape[0]):\n",
        "  dictionary[data['Id'][word]]=data['Text'][word]\n",
        "\n",
        "# print(dictionary)\n",
        "def access_text_using_id(id_no):\n",
        "  print(dictionary[id_no])\n",
        "\n",
        "# access_text_using_id(57)\n",
        "\n",
        "\n",
        "Train=pd.read_csv('/content/Test_Data.csv', header=None)\n",
        "X = Train.iloc[:,0:].values\n",
        "s1 = X[:,0]\n",
        "s2 = X[:,1]\n",
        "# s5 = X[:,2]\n",
        "\n",
        "s3=[]\n",
        "s4=[]\n",
        "for s in s1:\n",
        "    s3.append(dictionary[s])\n",
        "index=0\n",
        "for s in s2:\n",
        "    s4.append(dictionary[s])\n",
        "# for i in range (5):\n",
        "#     print(s3)"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2022-11-09T13:04:55.531487Z",
          "iopub.execute_input": "2022-11-09T13:04:55.532584Z",
          "iopub.status.idle": "2022-11-09T13:04:55.812363Z",
          "shell.execute_reply.started": "2022-11-09T13:04:55.532529Z",
          "shell.execute_reply": "2022-11-09T13:04:55.811191Z"
        },
        "trusted": true,
        "id": "9Cxiwfq92F4m"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(s1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:05:00.334656Z",
          "iopub.execute_input": "2022-11-09T13:05:00.335983Z",
          "iopub.status.idle": "2022-11-09T13:05:00.342405Z",
          "shell.execute_reply.started": "2022-11-09T13:05:00.335931Z",
          "shell.execute_reply": "2022-11-09T13:05:00.341345Z"
        },
        "trusted": true,
        "id": "Ow_qrTVT2F4n",
        "outputId": "77bf472a-041c-4305-c400-2ba647405c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[838 905 859 ... 851 829 846]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(s3[3])\n",
        "print(s4[3])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:05:01.752711Z",
          "iopub.execute_input": "2022-11-09T13:05:01.753907Z",
          "iopub.status.idle": "2022-11-09T13:05:01.760716Z",
          "shell.execute_reply.started": "2022-11-09T13:05:01.753836Z",
          "shell.execute_reply": "2022-11-09T13:05:01.759559Z"
        },
        "trusted": true,
        "id": "lz_9d47N2F4n",
        "outputId": "37571871-d69d-43d6-afdd-968944234c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "She will not be able to understand all these aspects in a day .\nHe must possess all the qualifications necessary to become a Member of Lok Sabha .\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/ComparisonWords_big (1).csv') \n",
        "mylist_compare = df['Words'].tolist()\n",
        "print(mylist_compare)\n",
        "\n",
        "df = pd.read_csv('/content/FeminineStereotype.csv')\n",
        "mylist_feminine_stereotype = df['Feminine'].tolist()\n",
        "\n",
        "df = pd.read_csv('/content/MasculineStereotype.csv')\n",
        "mylist_masculine_stereotype = df['Masculine'].tolist()\n",
        "\n",
        "df = pd.read_csv('/content/Masculine.csv')\n",
        "mylist_masculine = df['Male'].tolist()\n",
        "\n",
        "df=pd.read_csv('/content/Feminine.csv')\n",
        "mylist_feminine = df['Female'].tolist()\n",
        "# print(mylist_gender)\n",
        "\n",
        "df = pd.read_csv('/content/Negation.csv') \n",
        "mylist_negation = df['Negation'].tolist()\n",
        "\n",
        "def check_comparison_word(word):\n",
        "    if word in mylist_compare:\n",
        "        return 1\n",
        "    \n",
        "def check_masculine_word(word):\n",
        "    if word in mylist_masculine:\n",
        "        return 1\n",
        "    \n",
        "def check_feminine_word(word):\n",
        "    if word in mylist_feminine:\n",
        "        return 1\n",
        "    \n",
        "def check_feminine_stereotype_word(word):\n",
        "    if word in mylist_feminine_stereotype:\n",
        "        return 1\n",
        "\n",
        "def check_masculine_stereotype_word(word):\n",
        "    if word in mylist_masculine_stereotype:\n",
        "        return 1\n",
        "\n",
        "def check_negation_word(word):\n",
        "    if word in mylist_negation:\n",
        "        return 1"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2022-11-09T13:05:03.036016Z",
          "iopub.execute_input": "2022-11-09T13:05:03.037347Z",
          "iopub.status.idle": "2022-11-09T13:05:03.067692Z",
          "shell.execute_reply.started": "2022-11-09T13:05:03.037291Z",
          "shell.execute_reply": "2022-11-09T13:05:03.066588Z"
        },
        "trusted": true,
        "id": "H58zlvUS2F4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c3d13e-6d68-4ddc-bb6a-3e0617f0960f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['exceptional', 'improved', 'superior', 'improving', 'well', 'more', 'more', 'advance', 'beat', 'correct', 'enhance', 'exceed', 'excel', 'raise', 'surpass', 'predominant', 'exceptional', 'improved', 'superior', 'assertive', 'commanding', 'effective', 'leading', 'main', 'powerful', 'predominant', 'preeminent', 'prevailing', 'prevalent', 'principal', 'absolute', 'admirable', 'awesome', 'bad', 'best', 'exceptional', 'fantastic', 'fine', 'good', 'marvelous', 'perfect', 'positive', 'terrific', 'tough', 'tremendous', 'wonderful', 'exceptional', 'inimitable', 'transcendent', 'unmatched', 'unparalleled', 'catchy', 'decisive', 'enduring', 'eventful', 'extraordinary', 'famous', 'great', 'historic', 'important', 'impressive', 'indelible', 'interesting', 'meaningful', 'momentous', 'monumental', 'notable', 'remarkable', 'terrific', 'unforgettable', 'dominant', 'dominating', 'main', 'potent', 'prevailing', 'prevalent', 'weighty', 'distinguished', 'dominant', 'main', 'outstanding', 'peerless', 'predominant', 'renowned', 'transcendent', 'ultimate', 'admirable', 'exceptional', 'first-rate', 'good', 'high-caliber', 'preferable', 'remarkable', 'superhuman', 'magnificent', 'outstanding', 'peerless', 'superb', 'transcendent', 'unparalleled', 'colossal', 'gigantic', 'imposing', 'lofty', 'magnificent', 'massive', 'mighty', 'monumental', 'prodigious', 'soaring', 'stately', 'tall', 'abstract', 'fantastic', 'otherworldly', 'sublime', 'supernatural', 'ultimate', 'preeminent', 'transcendent', 'utmost', 'peerless', 'unmatched', 'unparalleled', 'unrivaled', 'unsurpassed', 'exceeding', 'also', 'extra', 'further', 'higher', 'new', 'other', 'also', 'better', 'further', 'over', 'too', 'exceptional', 'improved', 'superior', 'admirable', 'exceptional', 'first-rate', 'good', 'high-caliber', 'preferable', 'remarkable', 'superhuman', 'more', 'also', 'extra', 'further', 'higher', 'new', 'other', 'also', 'better', 'further', 'over', 'too', 'outstanding', 'distinguished', 'eminent', 'great', 'high-profile', 'leading', 'notable', 'noted', 'notorious', 'outstanding', 'popular', 'preeminent', 'renowned', 'respected', 'well-known', 'desirable', 'excellent', 'preferred', 'superior', 'exceptional', 'improved', 'superior', 'improving', 'well', 'exceptional', 'improved', 'superior', 'constructor', 'assembler', 'improving', 'well', 'admirable', 'exceptional', 'first-rate', 'good', 'high-caliber', 'preferable', 'remarkable', 'superhuman', 'boss', 'manager', 'principal', 'ruler', 'supervisor', 'exceptional', 'improved', 'superior', 'lesser', 'secondary', 'indifferent', 'lousy', 'mediocre', 'substandard', 'bad', 'poor', 'more', 'exceptional', 'improved', 'superior', 'improving', 'well', 'more', 'further', 'also', 'better', 'further', 'over', 'too', 'beat', 'eclipse', 'exceed', 'outpace', 'outperform', 'outstrip', 'outweigh', 'pass', 'rank', 'top', 'finest', 'first', 'first-rate', 'leading', 'outstanding', 'perfect', 'terrific', 'choice', 'favorite', 'beat', 'blank', 'conquer', 'outclass', 'outdo', 'outshine', 'overcome', 'surpass', 'take care of', 'trounce', 'dominant', 'elite', 'excellent', 'finest', 'leading', 'preeminent', 'primary', 'principal', 'cap', 'ceiling', 'cover', 'face', 'head', 'height', 'lid', 'peak', 'point', 'roof', 'surface', 'tip', 'best', 'head', 'cap', 'climb', 'cover', 'face', 'finish', 'beat', 'eclipse', 'exceed', 'outstrip', 'total', 'trim', 'farther', 'more', 'again', 'also', 'farther', 'then', 'yet', 'encourage', 'expedite', 'facilitate', 'hasten', 'help', 'promote', 'speed', 'container', 'boost', 'development', 'escalation', 'expansion', 'gain', 'hike', 'increment', 'inflation', 'merger', 'raise', 'rise', 'surge', 'upsurge', 'upturn', 'advance', 'boost', 'broaden', 'build', 'build up', 'deepen', 'develop', 'double', 'enhance', 'enlarge', 'escalate', 'expand', 'extend', 'further', 'heighten', 'intensify', 'multiply', 'raise', 'reinforce', 'rise', 'step up', 'strengthen', 'swell', 'triple', 'widen', 'contraction', 'cutback', 'decline', 'discount', 'downturn', 'loss', 'reduction', 'shrinkage', 'abate', 'curb', 'curtail', 'cut down', 'decline', 'depreciate', 'deteriorate', 'diminish', 'drop', 'drop off', 'dwindle', 'ease', 'ebb', 'fall off', 'lessen', 'lower', 'reduce', 'shrink', 'sink', 'slacken', 'slash', 'slump', 'soften', 'subside', 'wane', 'weaken', 'come through', 'outdo', 'shine', 'transcend', 'eclipse', 'outpace', 'outstrip', 'top', 'crush', 'overthrow', 'quell', 'rout', 'subdue', 'subjugate', 'surmount', 'vanquish', 'achieve', 'annex', 'occupy', 'overcome', 'overrun', 'seize', 'eclipse', 'excel', 'outclass', 'outdistance', 'outfox', 'outmaneuver', 'outshine', 'outsmart', 'outstrip', 'surpass', 'transcend', 'conquer', 'crush', 'overpower', 'overwhelm', 'reduce', 'stun', 'surmount', 'survive', 'weather', 'win', 'celebration', 'joy', 'pride', 'accomplishment', 'coup', 'feat', 'gain', 'grand slam', 'success', 'win', 'celebrate', 'conquer', 'dominate', 'flourish', 'overcome', 'overwhelm', 'prevail', 'prosper', 'sweep', 'thrive', 'trounce', 'win', 'outperform', 'outplay', 'transcend', 'accessible', 'advantageous', 'applicable', 'conducive', 'constructive', 'convenient', 'cooperative', 'crucial', 'essential', 'favorable', 'friendly', 'important', 'invaluable', 'practical', 'productive', 'profitable', 'significant', 'suitable', 'supportive', 'sympathetic', 'timely', 'useful', 'valuable', 'developing', 'gamesmanship', 'analyze', 'contrast', 'correlate', 'equal', 'match', 'measure', 'study', 'connect', 'correlate', 'equal', 'link', 'match', 'relate', 'analyze', 'contrast', 'correlate', 'equal', 'match', 'measure', 'study', 'connect', 'correlate', 'equal', 'link', 'match', 'relate', 'depress', 'drop', 'reduce', 'sink', 'curtail', 'cut', 'cut down', 'decrease', 'depreciate', 'devalue', 'diminish', 'downgrade', 'lessen', 'pare', 'scale down', 'slash', 'soften', 'knock off', 'depress', 'devalue', 'downgrade', 'chiefly', 'exclusively', 'notably', 'principally', 'specially', 'specifically', 'better', 'surpassing', 'more', 'finer', 'greater', 'more', 'prominent', 'preferable', 'worthier', 'fitter', 'stronger', 'sharper', 'superior', 'worthier', 'inferior', 'worse', 'smaller', 'bigger', 'higher', 'healthier', 'longer', 'surpass', 'best ', 'top', 'further', 'cooler', 'increase', 'decrease', 'excel', 'exceed', 'conquer', 'outdo', 'overcome', 'triumph', 'outshine', 'bettering', 'compare', 'compares', 'higher', 'lower', 'than', 'especially']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing of Data"
      ],
      "metadata": {
        "id": "89FtcQE-2F4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pta8y9f14eFb",
        "outputId": "515bc45a-2e87-42a8-bd5f-f909aeedd529"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens1 = []\n",
        "tokens2 = []\n",
        "tokens1 = [word_tokenize(str(sentence)) for sentence in s3]\n",
        "tokens2 = [word_tokenize(str(sentence)) for sentence in s4]\n",
        "\n",
        "rm1 = []\n",
        "for w in tokens1:\n",
        "    sm = re.sub('[^A-Za-z]',' ', str(w))\n",
        "    x = re.split(\"\\s\", sm)\n",
        "    rm1.append(x)\n",
        "    \n",
        "rm2 = []\n",
        "for w in tokens2:\n",
        "    sm2 = re.sub('[^A-Za-z]',' ', str(w))\n",
        "    x2 = re.split(\"\\s\", sm2)\n",
        "    rm2.append(x2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:05:15.965321Z",
          "iopub.execute_input": "2022-11-09T13:05:15.965923Z",
          "iopub.status.idle": "2022-11-09T13:06:38.718923Z",
          "shell.execute_reply.started": "2022-11-09T13:05:15.965872Z",
          "shell.execute_reply": "2022-11-09T13:06:38.717666Z"
        },
        "trusted": true,
        "id": "925yJarP2F4p"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(rm1[3])\n",
        "# print(rm2[4])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-07T17:36:20.513343Z",
          "iopub.execute_input": "2022-11-07T17:36:20.513759Z",
          "iopub.status.idle": "2022-11-07T17:36:20.519816Z",
          "shell.execute_reply.started": "2022-11-07T17:36:20.513728Z",
          "shell.execute_reply": "2022-11-07T17:36:20.518915Z"
        },
        "trusted": true,
        "id": "oGn0gaHW2F4p",
        "outputId": "faf32e4a-9912-44ee-dc80-a10acde2f58c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '', 'She', '', '', '', 'has', '', '', '', 'to', '', '', '', 'shoulder', '', '', '', 'and', '', '', '', 'manage', '', '', '', 'various', '', '', '', 'responsibilities', '', '', '', 'to', '', '', '', 'run', '', '', '', 'the', '', '', '', 'family', '', '', '', 'in', '', '', '', 'proper', '', '', '', 'order', '', '', '', '', '', '', '']\n",
            "['', '', 'We', '', '', '', 'saw', '', '', '', 'that', '', '', '', 'the', '', '', '', 'customs', '', '', '', 'of', '', '', '', 'the', '', '', '', 'tribe', '', '', '', 'as', '', '', '', 'understood', '', '', '', 'by', '', '', '', 'all', '', '', '', 'the', '', '', '', 'adult', '', '', '', 'male', '', '', '', 'members', '', '', '', 'of', '', '', '', 'the', '', '', '', 'community', '', '', '', 'were', '', '', '', 'very', '', '', '', 'important', '', '', '', 'in', '', '', '', 'conducting', '', '', '', 'the', '', '', '', 'activities', '', '', '', 'of', '', '', '', 'the', '', '', '', 'community', '', '', '', '', '', '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing whitespaces    \n",
        "for sent in rm1:\n",
        "    while '' in sent:\n",
        "        sent.remove('')\n",
        "\n",
        "for sent in rm2:\n",
        "    while '' in sent:\n",
        "        sent.remove('')\n",
        "        \n",
        "# Lowercasing\n",
        "low1 = []\n",
        "for i in rm1:\n",
        "    i = [x.lower() for x in i]\n",
        "    low1.append(i)\n",
        "\n",
        "low2 = []\n",
        "for i in rm2:\n",
        "    i = [x.lower() for x in i]\n",
        "    low2.append(i)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:06:52.395116Z",
          "iopub.execute_input": "2022-11-09T13:06:52.395559Z",
          "iopub.status.idle": "2022-11-09T13:07:20.446999Z",
          "shell.execute_reply.started": "2022-11-09T13:06:52.395522Z",
          "shell.execute_reply": "2022-11-09T13:07:20.445747Z"
        },
        "trusted": true,
        "id": "8j2xcPJ_2F4q"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(low1[3])\n",
        "# print(low2[3])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-06T18:15:43.070908Z",
          "iopub.execute_input": "2022-11-06T18:15:43.071359Z",
          "iopub.status.idle": "2022-11-06T18:15:43.078702Z",
          "shell.execute_reply.started": "2022-11-06T18:15:43.071292Z",
          "shell.execute_reply": "2022-11-06T18:15:43.077543Z"
        },
        "trusted": true,
        "id": "nIMw2qrl2F4q",
        "outputId": "c111f373-cad5-410c-d8e1-38c6aa16ffe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['she', 'has', 'to', 'shoulder', 'and', 'manage', 'various', 'responsibilities', 'to', 'run', 'the', 'family', 'in', 'proper', 'order']\n",
            "['in', 'such', 'case', 'he', 'can', 'use', 'his', 'scarce', 'means', 'to', 'satisfy', 'the', 'prioritized', 'wants', 'only']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:07:24.274892Z",
          "iopub.execute_input": "2022-11-09T13:07:24.276333Z",
          "iopub.status.idle": "2022-11-09T13:07:24.669671Z",
          "shell.execute_reply.started": "2022-11-09T13:07:24.276274Z",
          "shell.execute_reply": "2022-11-09T13:07:24.668346Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XA6zsBt2F4r",
        "outputId": "a778ce06-7d89-412b-faeb-2de59567cf69"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W_MSIk0Jsqm",
        "outputId": "f530ef30-a128-4a19-f9ec-5ebef144b7c7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rWncWDgKBFv",
        "outputId": "4eb6950c-e0b4-4fb9-e3b9-26aa02bd56de"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatozation\n",
        "lemma1 = []\n",
        "wnl = WordNetLemmatizer()\n",
        "for sent in low1:\n",
        "    tokens = [wnl.lemmatize(w) for w in sent]\n",
        "    lemma1.append(tokens)\n",
        "    \n",
        "lemma2 = []\n",
        "for sent in low2:\n",
        "    tok = [wnl.lemmatize(se) for se in sent]\n",
        "    lemma2.append(tok)\n",
        "    \n",
        "# Removing Stopwords\n",
        "filter_words1 = []\n",
        "Stopwords = set(stopwords.words('english'))\n",
        "\n",
        "for sent in lemma1:\n",
        "    tokens = [w for w in sent if w not in Stopwords or w in mylist_masculine or w in mylist_feminine]\n",
        "    filter_words1.append(tokens)\n",
        "    \n",
        "filter_words2 = []\n",
        "for sent in lemma2:\n",
        "    tokens2 = [w for w in sent if w not in Stopwords or w in mylist_masculine or w in mylist_feminine]\n",
        "    filter_words2.append(tokens2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:07:29.824531Z",
          "iopub.execute_input": "2022-11-09T13:07:29.824948Z",
          "iopub.status.idle": "2022-11-09T13:08:08.806571Z",
          "shell.execute_reply.started": "2022-11-09T13:07:29.824917Z",
          "shell.execute_reply": "2022-11-09T13:08:08.805472Z"
        },
        "trusted": true,
        "id": "WdvnYHDd2F4r"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(filter_words2[22])\n",
        "# print(filter_words1[22])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-07T17:52:48.881050Z",
          "iopub.execute_input": "2022-11-07T17:52:48.881485Z",
          "iopub.status.idle": "2022-11-07T17:52:48.888014Z",
          "shell.execute_reply.started": "2022-11-07T17:52:48.881451Z",
          "shell.execute_reply": "2022-11-07T17:52:48.886865Z"
        },
        "trusted": true,
        "id": "wV7WXZ-l2F4s",
        "outputId": "bba7e926-7756-4545-cfe6-b85313054c05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['men', 'started', 'wearing', 'tree', 'bark', 'cover', 'modesty']\n",
            "['death', 'mallasarja', 'she', 'fought', 'bravely', 'british', 'she', 'ha', 'called', 'brave', 'woman']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_para_for_comparison(para):\n",
        "    for word in para:\n",
        "        if(check_comparison_word(word)==1):\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def check_para_for_negation(para):\n",
        "    for word in para:\n",
        "        if(check_negation_word(word)==1):\n",
        "            return 1\n",
        "    return 0"
      ],
      "metadata": {
        "id": "PFktKmOLP-5V"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_of_ones_male=0\n",
        "count_of_ones_female=0\n",
        "def check_para_for_male(para):\n",
        "    global count_of_ones_male\n",
        "    for word in para:\n",
        "        count_of_ones_male+=1\n",
        "        if(check_masculine_word(word)==1):\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def check_para_for_female(para):\n",
        "    global count_of_ones_female\n",
        "    for word in para:\n",
        "        count_of_ones_female+=1\n",
        "        if(check_feminine_word(word)==1):\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def check_para_for_female_stereotype(para):\n",
        "    for word in para:\n",
        "        if(check_feminine_stereotype_word(word)==1):\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def check_para_for_male_stereotype(para):\n",
        "    for word in para:\n",
        "        if(check_masculine_stereotype_word(word)==1):\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "gender_check1=[]\n",
        "for text in filter_words1:\n",
        "    count_of_ones_male=0\n",
        "    count_of_ones_female=0\n",
        "    if(check_para_for_male(text) == check_para_for_female(text)):\n",
        "        # gender_check1.append(0)\n",
        "        if(check_para_for_male(text) == 1):\n",
        "            if(check_para_for_comparison(text) and not check_para_for_negation(text)):\n",
        "                gender_check1.append(1)\n",
        "\n",
        "            elif(count_of_ones_male < count_of_ones_female):\n",
        "                gender_check1.append(1)\n",
        "            \n",
        "            else:\n",
        "                gender_check1.append(0)\n",
        "        else:\n",
        "            gender_check1.append(0)\n",
        "            \n",
        "    elif(check_para_for_male(text) == 1):\n",
        "        if(check_feminine_stereotype_word(word) == 1):\n",
        "          gender_check1.append(0)\n",
        "        else:\n",
        "          gender_check1.append(1)\n",
        "    elif(check_para_for_female(text) == 1):\n",
        "        if(check_masculine_stereotype_word(word) == 1):\n",
        "          gender_check1.append(0)\n",
        "        else:\n",
        "          gender_check1.append(1)\n",
        "\n",
        "        # gender_check1.append(1)\n",
        "    \"\"\"\n",
        "    masculine + feminine = unbiased(0)\n",
        "    only masculine or only feminine = biased(1)\n",
        "    \"\"\"\n",
        "    \n",
        "#print(\"Set1 Gender count: Number of ones:\", count_of_ones, \"Number of zeroes: \", len(gender_check1)-count_of_ones)\n",
        "    \n",
        "count_of_ones=0\n",
        "gender_check2=[]\n",
        "for text in filter_words2:\n",
        "    count_of_ones_male=0\n",
        "    count_of_ones_female=0\n",
        "    if(check_para_for_male(text) == check_para_for_female(text)):\n",
        "        # gender_check1.append(0)\n",
        "        if(check_para_for_male(text) == 1):\n",
        "            if(check_para_for_comparison(text) and not check_para_for_negation(text)):\n",
        "                gender_check2.append(1)\n",
        "\n",
        "            elif(count_of_ones_male < count_of_ones_female):\n",
        "                gender_check2.append(1)\n",
        "            \n",
        "            else:\n",
        "                gender_check2.append(0)\n",
        "        else:\n",
        "            gender_check2.append(0)\n",
        "            \n",
        "    elif(check_para_for_male(text) == 1):\n",
        "        if(check_feminine_stereotype_word(word) == 1):\n",
        "          gender_check2.append(0)\n",
        "        else:\n",
        "          gender_check2.append(1)\n",
        "    elif(check_para_for_female(text) == 1):\n",
        "        if(check_masculine_stereotype_word(word) == 1):\n",
        "          gender_check2.append(0)\n",
        "        else:\n",
        "          gender_check2.append(1)\n",
        "\n",
        "    \n",
        "#print(\"Set2 Gender Count: Number of ones:\", count_of_ones, \"Number of zeroes: \", len(gender_check1)-count_of_ones)\n",
        "    \n",
        "length_of_dataset=len(gender_check1)\n",
        "# print(gender_check2)\n",
        "# print(gender_check1)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:11:14.532139Z",
          "iopub.execute_input": "2022-11-09T13:11:14.532530Z",
          "iopub.status.idle": "2022-11-09T13:11:19.322786Z",
          "shell.execute_reply.started": "2022-11-09T13:11:14.532500Z",
          "shell.execute_reply": "2022-11-09T13:11:19.321363Z"
        },
        "trusted": true,
        "id": "F3wJrB7s2F4s"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(comparison_check2[73])\n",
        "# print(filter_words2[4])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:11:38.115951Z",
          "iopub.execute_input": "2022-11-09T13:11:38.116648Z",
          "iopub.status.idle": "2022-11-09T13:11:38.122579Z",
          "shell.execute_reply.started": "2022-11-09T13:11:38.116606Z",
          "shell.execute_reply": "2022-11-09T13:11:38.121380Z"
        },
        "trusted": true,
        "id": "DQF4XQVX2F4t",
        "outputId": "348426bb-2c78-451b-dc3c-61c09c0afb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "['he', 'spends', 'his', 'earned', 'money', 'buy', 'essential', 'good', 'satisfy', 'his', 'want', 'consumption', 'good']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_of_ones=0\n",
        "gender_and_compare_final=[]\n",
        "for i in range(length_of_dataset):\n",
        "    if(gender_check1[i] == gender_check2[i]):\n",
        "        gender_and_compare_final.append(0)\n",
        "    else:\n",
        "        gender_and_compare_final.append(1)\n",
        "        count_of_ones+=1\n",
        "print(\"Number of ones\", count_of_ones, \"Number of zeroes\", length_of_dataset-count_of_ones)\n",
        "# print(gender_and_compare_final)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:11:50.280413Z",
          "iopub.execute_input": "2022-11-09T13:11:50.280820Z",
          "iopub.status.idle": "2022-11-09T13:11:50.339998Z",
          "shell.execute_reply.started": "2022-11-09T13:11:50.280786Z",
          "shell.execute_reply": "2022-11-09T13:11:50.338754Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz1XeZ4b2F4v",
        "outputId": "334504c0-8a16-44e3-aa4c-08f3817d66b9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ones 2602 Number of zeroes 2398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FastText\n",
        "FastText is an extension to Word2Vec proposed by Facebook in 2016. Instead of feeding individual words into the Neural Network, FastText breaks words into several n-grams (sub-words). For instance, the tri-grams for the word apple is app, ppl, and ple (ignoring the starting and ending of boundaries of words). The word embedding vector for apple will be the sum of all these n-grams. After training the Neural Network, we will have word embeddings for all the n-grams given the training dataset. Rare words can now be properly represented since it is highly likely that some of their n-grams also appears in other words.\n"
      ],
      "metadata": {
        "id": "LWl0kftl2F4w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-07T17:42:54.038202Z",
          "iopub.execute_input": "2022-11-07T17:42:54.038592Z",
          "iopub.status.idle": "2022-11-07T17:42:55.472327Z",
          "shell.execute_reply.started": "2022-11-07T17:42:54.038562Z",
          "shell.execute_reply": "2022-11-07T17:42:55.470287Z"
        },
        "trusted": true,
        "id": "pw9F_KdG2F4w",
        "outputId": "2d024548-cec7-489f-c2e5-6d0a2a41060f"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_27/897810521.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'woman'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'man'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mvocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0;34m\"The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0;34m\"Use KeyedVector's .key_to_index dict, .index_to_key list, and methods \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0;34m\".get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
          ],
          "ename": "AttributeError",
          "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine Similarity\n",
        "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. The cosine of 0° is 1, and it is less than 1 for any angle in the interval (0, π] radians.\n"
      ],
      "metadata": {
        "id": "EEechKvU2F4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making a new row\n",
        "Train['Masculine and Feminine check'] = gender_and_compare_final"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:12:02.605805Z",
          "iopub.execute_input": "2022-11-09T13:12:02.606229Z",
          "iopub.status.idle": "2022-11-09T13:12:02.656536Z",
          "shell.execute_reply.started": "2022-11-09T13:12:02.606194Z",
          "shell.execute_reply": "2022-11-09T13:12:02.655151Z"
        },
        "trusted": true,
        "id": "2PWTXNcG2F4_"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting an output file\n",
        "Train.to_csv(\"output.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:12:05.250241Z",
          "iopub.execute_input": "2022-11-09T13:12:05.250647Z",
          "iopub.status.idle": "2022-11-09T13:12:05.536672Z",
          "shell.execute_reply.started": "2022-11-09T13:12:05.250616Z",
          "shell.execute_reply": "2022-11-09T13:12:05.535268Z"
        },
        "trusted": true,
        "id": "7iiNQhF52F4_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "# sklearn.metrics.accuracy_score(s5, gender_and_compare_final)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-09T13:12:08.120848Z",
          "iopub.execute_input": "2022-11-09T13:12:08.121800Z",
          "iopub.status.idle": "2022-11-09T13:12:08.192142Z",
          "shell.execute_reply.started": "2022-11-09T13:12:08.121750Z",
          "shell.execute_reply": "2022-11-09T13:12:08.190903Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfNArk0n2F5A",
        "outputId": "8d70e407-38a9-4dd8-87a3-25c303822904"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8544625272105317"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JLR5mS0s2F5A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}